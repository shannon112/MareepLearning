(robotpower) ➜  hw11_gan_img_generation git:(master) ✗ python train.py ~/Downloads/faces/ model
Generator_dropout(
  (l1): Sequential(
    (0): Linear(in_features=100, out_features=8192, bias=False)
    (1): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (l2_5): Sequential(
    (0): Sequential(
      (0): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Sequential(
      (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Sequential(
      (0): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (3): Dropout(p=0.5)
    (4): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))
    (5): Tanh()
  )
)
Discriminator_dropout(
  (ls): Sequential(
    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    (1): LeakyReLU(negative_slope=0.2)
    (2): Sequential(
      (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2)
    )
    (3): Sequential(
      (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2)
    )
    (4): Sequential(
      (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2)
    )
    (5): Dropout(p=0.5)
    (6): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))
    (7): Sigmoid()
  )
)
dataset images len 71314
A sample in dataset torch.Size([3, 64, 64])
max and min in a image tensor(1.) tensor(-0.8039)
Epoch [1/30] 1115/1115 Loss_D: 0.3469 Loss_G: 3.0854 | Save some samples to ./log/Epoch_001.jpg.
Epoch [2/30] 1115/1115 Loss_D: 0.0484 Loss_G: 3.9228 | Save some samples to ./log/Epoch_002.jpg.
Epoch [3/30] 1115/1115 Loss_D: 0.3134 Loss_G: 3.5009 | Save some samples to ./log/Epoch_003.jpg.
Epoch [4/30] 1115/1115 Loss_D: 0.2157 Loss_G: 6.1899 | Save some samples to ./log/Epoch_004.jpg.
Epoch [5/30] 1115/1115 Loss_D: 0.0472 Loss_G: 2.2294 | Save some samples to ./log/Epoch_005.jpg.
Epoch [6/30] 1115/1115 Loss_D: 0.0657 Loss_G: 5.8346 | Save some samples to ./log/Epoch_006.jpg.
Epoch [7/30] 1115/1115 Loss_D: 0.0089 Loss_G: 6.6730 | Save some samples to ./log/Epoch_007.jpg.
Epoch [8/30] 1115/1115 Loss_D: 0.0684 Loss_G: 2.4133 | Save some samples to ./log/Epoch_008.jpg.
Epoch [9/30] 1115/1115 Loss_D: 0.1364 Loss_G: 1.2552 | Save some samples to ./log/Epoch_009.jpg.
Epoch [10/30] 1115/1115 Loss_D: 0.0026 Loss_G: 8.4590 | Save some samples to ./log/Epoch_010.jpg.
Epoch [11/30] 512/1115 Loss_D: 0.0000 Loss_G: 37.1083^CTraceback (most recent call last):
  File "train.py", line 72, in <module>
    f_imgs = G(z)
  File "/home/shannon/miniconda2/envs/robotpower/lib/python3.6/site-packages/torch/nn/modules/module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/shannon/Documents/MareepLearning/hw11_gan_img_generation/model.py", line 71, in forward
    y = self.l1(x)  # y = 8192
  File "/home/shannon/miniconda2/envs/robotpower/lib/python3.6/site-packages/torch/nn/modules/module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/shannon/miniconda2/envs/robotpower/lib/python3.6/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/home/shannon/miniconda2/envs/robotpower/lib/python3.6/site-packages/torch/nn/modules/module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/shannon/miniconda2/envs/robotpower/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 92, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shannon/miniconda2/envs/robotpower/lib/python3.6/site-packages/torch/nn/functional.py", line 1409, in linear
    if bias is not None:
KeyboardInterrupt
^C
(robotpower) ➜  hw11_gan_img_generation git:(master) ✗ 
(robotpower) ➜  hw11_gan_img_generation git:(master) ✗ 
(robotpower) ➜  hw11_gan_img_generation git:(master) ✗ python train.py ~/Downloads/faces/ model
Generator_dropout(
  (l1): Sequential(
    (0): Linear(in_features=100, out_features=8192, bias=False)
    (1): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (l2_5): Sequential(
    (0): Sequential(
      (0): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Sequential(
      (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Sequential(
      (0): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (3): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))
    (4): Tanh()
  )
)
Discriminator_dropout(
  (ls): Sequential(
    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    (1): LeakyReLU(negative_slope=0.2)
    (2): Sequential(
      (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2)
    )
    (3): Sequential(
      (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2)
    )
    (4): Sequential(
      (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2)
    )
    (5): Dropout(p=0.5)
    (6): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))
    (7): Sigmoid()
  )
)
dataset images len 71314
A sample in dataset torch.Size([3, 64, 64])
max and min in a image tensor(1.) tensor(-0.8039)
Epoch [1/30] 1115/1115 Loss_D: 0.2526 Loss_G: 3.6059 | Save some samples to ./log/Epoch_001.jpg.
Epoch [2/30] 1115/1115 Loss_D: 0.2586 Loss_G: 2.5221 | Save some samples to ./log/Epoch_002.jpg.
Epoch [3/30] 1115/1115 Loss_D: 0.0908 Loss_G: 5.8348 | Save some samples to ./log/Epoch_003.jpg.
Epoch [4/30] 1115/1115 Loss_D: 0.3712 Loss_G: 7.9314 | Save some samples to ./log/Epoch_004.jpg.
Epoch [5/30] 1115/1115 Loss_D: 0.1350 Loss_G: 3.6702 | Save some samples to ./log/Epoch_005.jpg.
Epoch [6/30] 1115/1115 Loss_D: 0.2622 Loss_G: 1.1521 | Save some samples to ./log/Epoch_006.jpg.
Epoch [7/30] 1115/1115 Loss_D: 0.2103 Loss_G: 2.7533 | Save some samples to ./log/Epoch_007.jpg.
Epoch [8/30] 1115/1115 Loss_D: 0.2274 Loss_G: 2.5893 | Save some samples to ./log/Epoch_008.jpg.
Epoch [9/30] 1115/1115 Loss_D: 0.1216 Loss_G: 4.6412 | Save some samples to ./log/Epoch_009.jpg.
Epoch [10/30] 1115/1115 Loss_D: 0.1863 Loss_G: 4.2762 | Save some samples to ./log/Epoch_010.jpg.
Epoch [11/30] 1115/1115 Loss_D: 0.0645 Loss_G: 3.8506 | Save some samples to ./log/Epoch_011.jpg.
Epoch [12/30] 1115/1115 Loss_D: 0.1030 Loss_G: 4.4575 | Save some samples to ./log/Epoch_012.jpg.
Epoch [13/30] 1115/1115 Loss_D: 0.0922 Loss_G: 4.7081 | Save some samples to ./log/Epoch_013.jpg.
Epoch [14/30] 1115/1115 Loss_D: 0.0807 Loss_G: 7.4045 | Save some samples to ./log/Epoch_014.jpg.
Epoch [15/30] 1115/1115 Loss_D: 0.0366 Loss_G: 3.8807 | Save some samples to ./log/Epoch_015.jpg.
Epoch [16/30] 1115/1115 Loss_D: 0.0499 Loss_G: 6.9988 | Save some samples to ./log/Epoch_016.jpg.
Epoch [17/30] 1115/1115 Loss_D: 0.0148 Loss_G: 6.4599 | Save some samples to ./log/Epoch_017.jpg.
Epoch [18/30] 1115/1115 Loss_D: 0.1985 Loss_G: 2.2653 | Save some samples to ./log/Epoch_018.jpg.
Epoch [19/30] 1115/1115 Loss_D: 0.2338 Loss_G: 1.7992 | Save some samples to ./log/Epoch_019.jpg.
Epoch [20/30] 1115/1115 Loss_D: 0.0569 Loss_G: 5.9748 | Save some samples to ./log/Epoch_020.jpg.
Epoch [21/30] 1115/1115 Loss_D: 0.4147 Loss_G: 2.7866 | Save some samples to ./log/Epoch_021.jpg.
Epoch [22/30] 1115/1115 Loss_D: 0.1706 Loss_G: 6.3343 | Save some samples to ./log/Epoch_022.jpg.
Epoch [23/30] 1115/1115 Loss_D: 0.2578 Loss_G: 2.0195 | Save some samples to ./log/Epoch_023.jpg.
Epoch [24/30] 1115/1115 Loss_D: 0.1314 Loss_G: 4.6919 | Save some samples to ./log/Epoch_024.jpg.
Epoch [25/30] 1115/1115 Loss_D: 0.0141 Loss_G: 5.5697 | Save some samples to ./log/Epoch_025.jpg.
Epoch [26/30] 1115/1115 Loss_D: 0.0724 Loss_G: 4.4337 | Save some samples to ./log/Epoch_026.jpg.
Epoch [27/30] 1115/1115 Loss_D: 1.0537 Loss_G: 0.8110 | Save some samples to ./log/Epoch_027.jpg.
Epoch [28/30] 1115/1115 Loss_D: 0.2015 Loss_G: 6.2738 | Save some samples to ./log/Epoch_028.jpg.
Epoch [29/30] 1115/1115 Loss_D: 0.0279 Loss_G: 7.8716 | Save some samples to ./log/Epoch_029.jpg.
Epoch [30/30] 1115/1115 Loss_D: 0.0618 Loss_G: 8.0410 | Save some samples to ./log/Epoch_030.jpg.
