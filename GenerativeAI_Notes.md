# å‰è¨€
å¿«é€Ÿç­†è¨˜ä¸€ä¸‹ä¸Šèª²å…§å®¹ï¼Œä»¥åˆ©æ—¥å¾ŒCtrl+Fæœå°‹keywordså’Œconcept

# 2024.02.24 ã€ç”Ÿæˆå¼AIå°è«– 2024ã€‘ç¬¬1è¬›ï¼šç”Ÿæˆå¼AIæ˜¯ä»€éº¼ï¼Ÿ 
- video: https://www.youtube.com/watch?v=JGtqpQXfJis
- slide: https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring-course-data/0223/0223_intro_gai.pdf
- ç”Ÿæˆå¼äººå·¥æ™ºæ…§ âŠ‚ äººå·¥æ™ºæ…§
  - äººå·¥æ™ºæ…§ (Artificial Intelligence, AI): è®“æ©Ÿå™¨å±•ç¾ã€Œæ™ºæ…§ã€
  - ç”Ÿæˆå¼äººå·¥æ™ºæ…§ (Generative AI, GenAI): æ©Ÿå™¨ç”¢ç”Ÿè¤‡é›œæœ‰çµæ§‹çš„ç‰©ä»¶
    - æ–‡ç« -ç”±æ–‡å­—æ‰€æ§‹æˆ, å½±åƒ-ç”±åƒç´ æ‰€çµ„æˆ, èªéŸ³-ç”±å–æ¨£é»æ§‹æˆ
    - i.g. ChatGPT ç”¨ Transformer
    - i.g. Stable Diffusion, Midjourney, DALLÂ·E ç”¨ Diffusion Model
- ç”Ÿæˆå¼äººå·¥æ™ºæ…§ âŠ‚ æ·±åº¦å­¸ç¿’ âŠ‚ æ©Ÿå™¨å­¸ç¿’ âŠ‚ äººå·¥æ™ºæ…§
  - æ©Ÿå™¨å­¸ç¿’ (Machine Learning) â‰ˆ æ©Ÿå™¨è‡ªå‹•å¾è³‡æ–™æ‰¾ä¸€å€‹å‡½å¼
    - i.g. å‡½å¼ ğ‘¦ = ğ‘“(ğ‘¥) = ğ‘ğ‘¥ + ğ‘, aå’Œb ç‚º åƒæ•¸ (Parameter)
    - i.g. æ©Ÿå™¨å­¸ç¿’å¯ä»¥æŠŠæœ‰ä¸Šè¬å€‹åƒæ•¸çš„å‡½å¼çš„åƒæ•¸æ‰¾å‡ºä¾† é€é è¨“ç·´, training (å­¸ç¿’, learning)
    - i.g. æœ‰äº†å‡½å¼å¾Œè¨ˆç®—ç­”æ¡ˆå« æ¸¬è©¦, testing (æ¨è«–, inference)
  - æ·±åº¦å­¸ç¿’(Deep Learning) æ˜¯ä¸€ç¨®æ©Ÿå™¨å­¸ç¿’æŠ€è¡“, ä½¿ç”¨ é¡ç¥ç¶“ç¶²è·¯ (Neural Network)
  - <img src="https://i.imgur.com/QTlrJ3k.png" height=200/>
- ç”Ÿæˆç­–ç•¥: æ–‡å­—æ¥é¾ 
  - æ©Ÿå™¨éœ€è¦èƒ½å¤ ç”¢ç”Ÿåœ¨è¨“ç·´æ™‚å¾ä¾†æ²’æœ‰çœ‹éçš„æ±è¥¿
    - åŸæœ¬ç”Ÿæ–‡ç«  å¯èƒ½æ€§ çª®ç›¡ç„¡ç›¡!
    - æ‹†è§£æˆä¸€é€£ä¸² æ–‡å­—æ¥é¾ or åƒç´ æ¥é¾ åˆ†é¡å•é¡Œ ç­”æ¡ˆæœ‰é™!
  - è¤‡é›œçš„ç‰©ä»¶ æ‹†è§£æˆè¼ƒå°çš„å–®ä½ ä¾ç…§æŸç¨®å›ºå®šçš„é †åºä¾åºç”Ÿæˆ å«Autoregressive Generation

# 2024.03.03 ã€ç”Ÿæˆå¼AIå°è«– 2024ã€‘ç¬¬2è¬›ï¼šä»Šæ—¥çš„ç”Ÿæˆå¼äººå·¥æ™ºæ…§å²å®³åœ¨å“ªè£¡ï¼Ÿå¾ã€Œå·¥å…·ã€è®Šç‚ºã€Œå·¥å…·äººã€ 
- video: https://www.youtube.com/watch?v=glBhOQ1_RkE
- slide: https://drive.google.com/file/d/1Ru6DUX8KrSzCvn2DN1-YluTyx5rw3QD3/view
- ä»Šæ—¥çš„ç”Ÿæˆå¼äººå·¥æ™ºæ…§å²å®³åœ¨å“ªè£¡? åŠŸèƒ½å–®ä¸€ -> æ²’æœ‰ç‰¹å®šåŠŸèƒ½(é€šç”¨å‹)
  - GPTç³»åˆ— ç‚ºOpenAIæ‰€é–‹ç™¼
  - Gemini ç‚ºGoogleæ‰€é–‹ç™¼
  - Llamaç³»åˆ— ç‚ºMetaé‡‹å‡ºçš„é–‹æºå¤§å‹èªè¨€æ¨¡å‹
  - TAIDEæ¨¡å‹ç‚ºLlama2æ¨¡å‹çµåˆè‡ºç£æ–‡åŒ–èˆ‡æ­£é«”ä¸­æ–‡èªæ–™ä¹‹è¡ç”Ÿæ¨¡å‹ (ä¾†è‡ªåœ‹ç§‘æœƒ-æ¨å‹•å¯ä¿¡ä»»ç”Ÿæˆå¼AIç™¼å±•å…ˆæœŸè¨ˆç•«)
- å¯èƒ½çš„ç ”ç©¶æ–¹å‘:
  - è©•ä¼°æ¨¡å‹(evaluation)å›°é›£ ä¸å¥½è©•ä¼°ç­”æ¡ˆä¹‹æ–¼å•é¡Œæ˜¯å¦å®Œç¾è¢«è§£æ±º
  - è¦é˜²æ­¢èªªå‡ºæœ‰å®³å…§å®¹
  - Improvement
    - æ”¹è®Šè‡ªå·±ä¾†å¼·åŒ–æ¨¡å‹ (improving inputs) - prompt engineering, [continue](https://github.com/shannon112/MareepLearning/blob/master/GenerativeAI_Notes.md#20240303%E7%94%9F%E6%88%90%E5%BC%8Fai%E5%B0%8E%E8%AB%96-2024%E7%AC%AC3%E8%AC%9B%E8%A8%93%E7%B7%B4%E4%B8%8D%E4%BA%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%A0%E5%8F%AF%E4%BB%A5%E8%A8%93%E7%B7%B4%E4%BD%A0%E8%87%AA%E5%B7%B1-%E4%B8%8A--%E7%A5%9E%E5%A5%87%E5%92%92%E8%AA%9E%E8%88%87%E6%8F%90%E4%BE%9B%E6%9B%B4%E5%A4%9A%E8%B3%87%E8%A8%8A)
    - è¨“ç·´è‡ªå·±çš„æ¨¡å‹ (improving parameters)

# 2024.03.03ã€ç”Ÿæˆå¼AIå°è«– 2024ã€‘ç¬¬3è¬›ï¼šè¨“ç·´ä¸äº†äººå·¥æ™ºæ…§ï¼Ÿä½ å¯ä»¥è¨“ç·´ä½ è‡ªå·± (ä¸Š) â€” ç¥å¥‡å’’èªèˆ‡æä¾›æ›´å¤šè³‡è¨Š 
- video: https://www.youtube.com/watch?v=A3Yx35KrSN0&t=1722s
- slide: https://drive.google.com/file/d/1JTexyex5hrHmNdrkXy-jOVKZlycODC7Y/view
- æ”¹è®Šè‡ªå·±ä¾†å¼·åŒ–æ¨¡å‹ (improving inputs) - prompt engineering
  - <img src="https://i.imgur.com/EekRhP4.png" height=200>
  - 1.ç¥å¥‡å’’èª (ä¸ä¸€å®šå°æ‰€æœ‰æ¨¡å‹ã€æ‰€æœ‰ä»»å‹™éƒ½é©ç”¨) => æœ€æœ‰å: Chain of Thought 
    - å«æ¨¡å‹æ€è€ƒ "Chain of Thought (CoT)"
      - i.g. Let's think step by step, 
      - Large Language Models are Zero-Shot Reasoners, https://arxiv.org/abs/2205.11916
    - å«æ¨¡å‹è§£é‡‹ä¸€ä¸‹è‡ªå·±çš„ç­”æ¡ˆ
      - i.g. Answer by starting with Analysis 
      - A Closer Look into Automatic Evaluation Using Large Language Models, https://arxiv.org/abs/2310.05657
      - Can Large Language Models Be an Alternative to Human Evaluations?, https://arxiv.org/abs/2305.01937
      - The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning, https://arxiv.org/abs/2205.03401
    - æƒ…ç·’å‹’ç´¢
      - i.g. This is very important to my career 
      - Large Language Models Understand and Can be Enhanced by Emotional Stimuli, https://arxiv.org/abs/2307.11760
    - æ›´å¤šçš„ç¥å¥‡å’’èª é©—è­‰éƒ½å¸‚å‚³èªª
      - i.g. No need to be polite like â€œpleaseâ€, â€œif you donâ€™t mindâ€, â€œthank youâ€, â€œI would like toâ€, etc., æœ‰ç¦®è²Œæ˜¯æ²’ç”¨çš„
      - i.g. Employ affirmative directives such as â€˜do,â€™ while steering clear of negative language like â€˜donâ€™tâ€™. æ­£é¢è¡¨è¿° å¥½éè² é¢è¡¨è¿°
      - i.g. Add â€œIâ€™m going to tip $xxx for a better solution!â€ èªªè¦çµ¦å°è²» æ˜¯æœ‰ç”¨çš„
      - i.g. Incorporate the following phrases: â€œYou will be penalizedâ€ èªªæœƒæœ‰è™•ç½° æ˜¯æœ‰ç”¨çš„
      - i.g. Add prompt â€œEnsure that your answer is unbiased and avoids relying on stereotypes.â€ è¦å…¶ä¸­ç«‹ç„¡åè¦‹ æ˜¯æœ‰ç”¨çš„
      - Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4, https://arxiv.org/abs/2312.16171
    - ç”¨å¢å¼·å¼å­¸ç¿’ (Reinforcement Learning, RL) æ‰¾ç¥å¥‡å’’èª
      - i.g. ä»»å‹™ç›®æ¨™:å›æ‡‰è¶Šé•·è¶Šå¥½, prompt: â€œways ways ways ways ways ways ways .......â€
      - Learning to Generate Prompts for Dialogue Generation through Reinforcement Learning, https://arxiv.org/abs/2206.03931
    - ç”¨å¤§å‹èªè¨€æ¨¡å‹ä¾† æ‰¾ç¥å¥‡å’’èª
      - i.g. Letâ€™s work this out in a step by step way to be sure we have the right answer. 
      - i.g. Take a deep breath and work on this problem step-by-step  
      - Large Language Models Are Human-Level Prompt Engineers, https://arxiv.org/abs/2211.01910
  - 2.æŠŠå‰æè¬›æ¸…æ¥š => æœ€æœ‰å: In-context Learning
    - æä¾›ç”Ÿæˆå¼AIåŸæœ¬ä¸æ¸…æ¥šçš„è³‡è¨Š
    - æä¾›ç¯„ä¾‹ In-context Learning - Language Models are Few-Shot Learners, https://arxiv.org/abs/2005.14165
      - æä¾›èˆ‡å˜—è©¦ç›¸åçš„ç¯„ä¾‹ï¼Œå¸Œæœ›èªè¨€æ¨¡å‹ç­”éŒ¯
        - ç„¡æ•ˆ Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? https://arxiv.org/abs/2202.12837
        - å°å¤§çš„å¼·çš„ æœ‰æ•ˆ Larger language models do in-context learning differently https://arxiv.org/abs/2303.03846
      - æä¾›ç½•è¦‹èªè¨€çš„æ•™ç§‘æ›¸ï¼Œå¸Œæœ›èªè¨€æ¨¡å‹èƒ½ç¿»è­¯
        - æœ‰æ•ˆ https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf

#2024.03.10 
- video: 
- slide: https://drive.google.com/file/d/1eVC4dx77Mba2_yMFe1_w4tXvIdSDTOCO/view?usp=sharing
- 3.æ‹†è§£ä»»å‹™
- e.g. åˆ†æ®µå¯«é•·ç¯‡å°èªª Re3 arxiv
- e.g. ç®—æ•¸å­¸æœ‰åˆ—å¼ CoT 
